ğŸ” Motor de Busca Inteligente
Um sistema de busca avanÃ§ado que combina busca web em tempo real com anÃ¡lise de IA para gerar resumos inteligentes e estruturados sobre qualquer tema.

ğŸš€ Novidade: OpenAI OSS 120B
Agora com os novos modelos open-source da OpenAI! Aproveite a qualidade OpenAI com a velocidade ultrarrÃ¡pida do GroqCloud.

ğŸ§  OpenAI OSS 120B: 500+ tokens/s com qualidade premium
âš¡ OpenAI OSS 20B: 1000+ tokens/s ultra rÃ¡pido
ğŸŒ 100% Open Source: TransparÃªncia total
âœ¨ Funcionalidades
ğŸ” Busca Web Inteligente: IntegraÃ§Ã£o com SerpAPI para resultados atualizados
ğŸ¤– AnÃ¡lise por IA: Resumos estruturados usando modelos de ponta
ğŸ“° Filtros Especializados: Busca geral ou focada em notÃ­cias
âš¡ Ultra Velocidade: Processamento em segundos via GroqCloud
ğŸ“š MÃºltiplas Fontes: Web, notÃ­cias e knowledge graphs
ğŸ¯ Interface Moderna: Design responsivo e intuitivo
ğŸ› ï¸ Tecnologias
Frontend: Streamlit (Python)
IA: OpenAI OSS, Llama 3.3, Mixtral (via GroqCloud)
Busca Web: SerpAPI
Gerenciamento: python-dotenv
ğŸ“‹ PrÃ©-requisitos
Python 3.8+
Chaves de API (gratuitas):
GroqCloud
SerpAPI (100 buscas gratuitas)
ğŸš€ InstalaÃ§Ã£o RÃ¡pida
1. Clone o repositÃ³rio
bash
git clone <url-do-repositorio>
cd motor-busca-inteligente
2. Instale as dependÃªncias
bash
pip install streamlit requests python-dotenv groq openai
3. Configure as variÃ¡veis de ambiente
Crie um arquivo .env na raiz do projeto:

env
# ObrigatÃ³rias
SERPAPI_KEY=sua_chave_serpapi_aqui
GROQ_API_KEY=sua_chave_groq_aqui

# Opcional (para modelos OpenAI o1)
OPENAI_API_KEY=sk-sua_chave_openai_aqui
4. Execute o aplicativo
bash
streamlit run app.py
ğŸ¯ Como Usar
Acesse http://localhost:8501 no seu navegador
Escolha o provedor de IA:
GroqCloud: Ultra rÃ¡pido (recomendado)
OpenAI: Para modelos o1 (reasoning)
Selecione o modelo:
openai/gpt-oss-120b (ğŸ”¥ Recomendado)
openai/gpt-oss-20b (mais rÃ¡pido)
Llama, Mixtral, Gemma2
Digite sua pesquisa
Receba anÃ¡lise completa em segundos!
ğŸ“Š Modelos DisponÃ­veis
ğŸ†• OpenAI OSS (via GroqCloud)
Modelo	ParÃ¢metros	Velocidade	Qualidade	Uso
openai/gpt-oss-120b	120B	500+ t/s	ğŸ† Excelente	AnÃ¡lises profundas
openai/gpt-oss-20b	20B	1000+ t/s	ğŸ“ Muito Boa	Uso geral rÃ¡pido
ğŸ¦™ Outros Modelos
Llama 3.3 70B: Meta's mais recente
Mixtral 8x7B: Melhor para contexto longo
Gemma2 9B: Google, eficiente
ğŸ§  OpenAI o1 (opcional)
o1: Reasoning avanÃ§ado (mais lento)
o1-mini: Reasoning rÃ¡pido
ğŸ¨ Interface
Principais Recursos
ğŸ” Busca Inteligente: Campo de entrada intuitivo
âš™ï¸ ConfiguraÃ§Ãµes: Sidebar com controles avanÃ§ados
ğŸ“Š MÃ©tricas: EstatÃ­sticas em tempo real
ğŸ“š Fontes Organizadas: Abas separadas por tipo
ğŸ”„ Cache Management: BotÃµes de limpeza integrados
Filtros de Busca
Geral: Resultados web + knowledge graphs
NotÃ­cias: Foco em conteÃºdo jornalÃ­stico atual
ğŸ“ Exemplo de Uso
python
# Busca: "inteligÃªncia artificial 2025"
# Resultado: Resumo estruturado com:

## ğŸ¯ Resumo Executivo
AnÃ¡lise das principais tendÃªncias...

## ğŸ“Š AnÃ¡lise Detalhada  
Desenvolvimento aprofundado dos temas...

## ğŸ” Insights Principais
- TendÃªncia 1: ExplicaÃ§Ã£o detalhada
- TendÃªncia 2: AnÃ¡lise contextual
- TendÃªncia 3: Perspectivas futuras

## ğŸ’¡ ConclusÃµes
SÃ­ntese final e consideraÃ§Ãµes...
ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas
ParÃ¢metros de IA
Temperature: Controle de criatividade (0.0 - 1.0)
Max Tokens: Tamanho do resumo (300 - 2000)
NÃºmero de Fontes: 3-20 resultados
ConfiguraÃ§Ãµes de Busca
Idioma: pt, en, es
PaÃ­s: br, us, es, global
Filtros de SeguranÃ§a: Ativo por padrÃ£o
ğŸš¨ SoluÃ§Ã£o de Problemas
Erros Comuns
âŒ "SERPAPI_KEY nÃ£o configurada"

bash
# Verifique se o arquivo .env existe e contÃ©m:
SERPAPI_KEY=sua_chave_aqui
âŒ "Modelo descontinuado"

bash
# Use os modelos atualizados:
openai/gpt-oss-120b  # âœ… Recomendado
llama-3.3-70b-versatile  # âœ… Alternativa
âŒ "Nenhum resultado encontrado"

Tente termos mais especÃ­ficos
Verifique conexÃ£o com internet
Teste com palavras-chave diferentes
Limpeza de Cache
Interface: BotÃµes ğŸ—‘ï¸ e ğŸ”„ na sidebar
Teclado: Pressione C na pÃ¡gina
Terminal: Ctrl+C e reinicie
ğŸ“ˆ Performance
Velocidades TÃ­picas
OpenAI OSS 120B: 500+ tokens/s (~2-5 segundos)
OpenAI OSS 20B: 1000+ tokens/s (~1-3 segundos)
Llama 3.3: 300+ tokens/s (~3-7 segundos)
Mixtral: 200+ tokens/s (~5-10 segundos)
Benchmarks
Qualidade: OSS 120B â‰ˆ GPT-4 level
Velocidade: 10x mais rÃ¡pido que APIs tradicionais
Custo: 80% mais barato que OpenAI oficial
ğŸ” SeguranÃ§a e Privacidade
ğŸ”’ Chaves Locais: APIs keys ficam no seu .env
ğŸš« Sem Logs: NÃ£o armazenamos suas pesquisas
ğŸ›¡ï¸ Filtros Seguros: ConteÃºdo filtrado automaticamente
ğŸŒ GDPR Compliant: Respeita regulamentaÃ§Ãµes
ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

Fork o projeto
Crie uma branch (git checkout -b feature/nova-funcionalidade)
Commit suas mudanÃ§as (git commit -am 'Adiciona nova funcionalidade')
Push para a branch (git push origin feature/nova-funcionalidade)
Abra um Pull Request
ğŸ“„ LicenÃ§a
Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo LICENSE para detalhes.

ğŸ™ Agradecimentos
OpenAI: Pelos modelos OSS revolucionÃ¡rios
GroqCloud: Pela infraestrutura ultrarrÃ¡pida
SerpAPI: Pela API de busca confiÃ¡vel
Streamlit: Pelo framework incrÃ­vel
Meta: Pelos modelos Llama open-source
ğŸ“ Suporte
Encontrou um bug ou tem uma sugestÃ£o?

ğŸ› Abra uma issue
ğŸ’¬ DiscussÃµes
ğŸ“§ Contato: [seu-email@exemplo.com]
ğŸ—ºï¸ Roadmap
âœ… ConcluÃ­do
 IntegraÃ§Ã£o OpenAI OSS
 Interface moderna
 MÃºltiplos provedores de IA
 Cache inteligente
ğŸ”„ Em Desenvolvimento
 ExportaÃ§Ã£o de relatÃ³rios (PDF/Word)
 HistÃ³rico de pesquisas
 AnÃ¡lise de sentimento
 Suporte a mÃºltiplos idiomas
ğŸ¯ Planejado
 API REST
 Plugin para navegadores
 AnÃ¡lise de imagens
 IntegraÃ§Ã£o com bases acadÃªmicas
<div align="center">
ğŸš€ Feito com â¤ï¸ e IA de ponta

â­ Star no GitHub | ğŸ› Reportar Bug | ğŸ’¡ Sugerir Feature

</div>
